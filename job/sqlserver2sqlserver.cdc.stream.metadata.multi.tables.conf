# CDC source connector only specify table name, source connector learns schema from database directly.
# Transform connector Metadata extracts metadata fields from source connector.
# Sink connector use metadata field to dynamically route data to different tables.
# This job reads change data from two tables in sqlserver database "company", and writes to two tables in sqlserver database "company_dwh".
# The two tables in database "company_dwh" are created automatically by sink connector.
# The two tables in database "company_dwh" have different table name and primary key.
# The table name and primary key are extracted from source connector by transform connector Metadata.
# The table name and primary key are passed to sink connector by variable substitution.

env {
    job.name = "sqlserver2sqlserver.cdc.stream.metadata"
    parallelism = 1
    job.mode = "STREAMING"
    checkpoint.interval = 10000
}

source {
  SqlServer-CDC {
    plugin_output = "source_result1"

    base-url = "jdbc:sqlserver://db02:1433;databaseName=company"
    startup.mode="initial"
    # startup.mode="latest"
    exactly_once = true
    username = "seatunnel_src"
    password = "Abcd1234"
    database-names = ["company"]
    table-names = ["company.dbo.emps","company.dbo.depts"]
  }
}

transform {
  Metadata {
    plugin_input = ["source_result1"]
    metadata_fields {
      Database = database
      Table = table
      RowKind = op
      EventTime = updated_at
      Delay = delay
    }
    plugin_output = "tran_result1"
  }
}

sink {
  Jdbc {
    plugin_input = ["tran_result1"]
    driver = com.microsoft.sqlserver.jdbc.SQLServerDriver
    url = "jdbc:sqlserver://db02:1433;databaseName=company_dwh"
    user = seatunnel_sink
    password = "Abcd1234"

    generate_sink_sql = true
    batch_size = 100
    schema_save_mode = "CREATE_SCHEMA_WHEN_NOT_EXIST"
    data_save_mode = "APPEND_DATA"

    database = "company_dwh"
    table = "DW_ETL.${table_name}"
    primary_keys = ["${primary_key}"]
  }
}