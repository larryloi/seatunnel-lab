env {
  parallelism = 1
  job.name = "sqlserver2paimon.cdc.stream.metadata.multi.table"
  job.mode = "STREAMING"
  checkpoint.interval = 5000
}

source {
  SqlServer-CDC {
    plugin_output = "source_result1"

    base-url = "jdbc:sqlserver://db02:1433;databaseName=company"
    startup.mode="initial"
    # startup.mode="latest"
    exactly_once = true
    username = "seatunnel_src"
    password = "Abcd1234"
    database-names = ["company"]
    table-names = ["company.dbo.emps","company.dbo.depts"]
  }
}

transform {
  RowKindExtractor {
    plugin_input = ["source_result1"]
    plugin_output = "row_kind_result"
    transform_type = "SHORT"
    }
  
  Sql {
    plugin_input = ["row_kind_result"]
    plugin_output = "sql_result"
    query = """
      SELECT *, NOW() ingested_at
      FROM row_kind_result
    """
  }

  FieldRename {
    plugin_input = "sql_result",
    plugin_output = "tran_result"
    replacements_with_regex = [
      {
        replace_from = "row_kind"
        replace_to = "__op"
      }
    ] 
  }
}

sink {
  Paimon {
    plugin_input = ["tran_result"]
    warehouse = "s3a://datalake/ods/"
    database="ods_${database_name}"
    table="${table_name}"
    paimon.hadoop.conf = {
        fs.s3a.access-key=seatunnel_sink
        fs.s3a.secret-key=Abcd1234
        fs.s3a.endpoint="http://db01:9000"
        fs.s3a.path.style.access=true
        fs.s3a.aws.credentials.provider=org.apache.hadoop.fs.s3a.SimpleAWSCredentialsProvider
    }
    paimon.table.write-props = {
        bucket = 2
        file.format = "parquet"
    }
  }
}